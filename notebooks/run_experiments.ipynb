{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1573225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INICIALIZANDO OPTIMIZACIONES\n",
      "============================================================\n",
      "Optimizaciones habilitadas\n",
      "CPU cores disponibles: 12\n",
      "Workers configurados: 8\n",
      "geopandas 1.1.2\n",
      "\n",
      "Provincias disponibles:\n",
      "  01. AZUAY\n",
      "  02. BOLIVAR\n",
      "  03. CARCHI\n",
      "  04. CAÑAR\n",
      "  05. CHIMBORAZO\n",
      "  06. COTOPAXI\n",
      "  07. EL ORO\n",
      "  08. ESMERALDAS\n",
      "  09. GALAPAGOS\n",
      "  10. GUAYAS\n",
      "  11. IMBABURA\n",
      "  12. LOJA\n",
      "  13. LOS RIOS\n",
      "  14. MANABI\n",
      "  15. MORONA SANTIAGO\n",
      "  16. NAPO\n",
      "  17. ORELLANA\n",
      "  18. PASTAZA\n",
      "  19. PICHINCHA\n",
      "  20. SANTA ELENA\n",
      "  21. SANTO DOMINGO DE LOS TSACHILAS\n",
      "  22. SUCUMBIOS\n",
      "  23. TUNGURAHUA\n",
      "  24. ZAMORA CHINCHIPE\n",
      "  25. PROVINCIA\n",
      "\n",
      "============================================================\n",
      "Intervalo: 2000-2024\n",
      "\n",
      "Modo publico: activado (data anonimizado)\n",
      "\n",
      "============================================================\n",
      "INICIANDO PROCESAMIENTO\n",
      "============================================================\n",
      "\n",
      "Limpieza previa: 4 carpetas __pycache__ eliminadas.\n",
      "Iniciando pipeline para BOLIVAR (15 etapas)...\n",
      "  01. Carga del raw\n",
      "  02. Normalización de campos\n",
      "  03. Filtro universo (SOCIEDAD)\n",
      "  04. Filtro provincia\n",
      "  05. Filtro codigos omitidos\n",
      "  06. QC raw\n",
      "  07. Colapso a RUC\n",
      "  08. QC RUC\n",
      "  09. Demografía y cohortes\n",
      "  10. Cantones y geografía\n",
      "  11. Macro sectores y actividades\n",
      "  12. KPIs de supervivencia\n",
      "  13. Figuras base\n",
      "  14. Comparativas / KM estratificado\n",
      "  15. Métricas ejecutivas\n",
      "----------------------------------------\n",
      "[  6.7% · 1/15] Carga del raw — 80,504 filas leídas desde data\\raw\\SRI_RUC_Bolivar.csv | tiempo 1s · ETA 8s\n",
      "[ 13.3% · 2/15] Normalización de campos — 80,504 filas normalizadas | tiempo 1s · ETA 5s\n",
      "[ 20.0% · 3/15] Filtro universo (SOCIEDAD) — 80,504 -> 4,052 registros SOCIEDAD | tiempo 55s · ETA 3m 41s\n",
      "[ 26.7% · 4/15] Filtro provincia — 4,052 -> 3,918 registros en BOLIVAR | tiempo 55s · ETA 2m 32s\n",
      "[ 33.3% · 5/15] Filtro codigos omitidos — 3,918 -> 1,968 excluyendo 6 codigos en CODIGO_CIIU | tiempo 55s · ETA 1m 51s\n",
      "[ 40.0% · 6/15] QC raw — QC raw listo (RUC únicos: 1606) | tiempo 55s · ETA 1m 23s\n",
      "[ 46.7% · 7/15] Colapso a RUC — 1,606 RUC en ruc_master.parquet | tiempo 1m 4s · ETA 1m 14s\n",
      "[ 53.3% · 8/15] QC RUC — QC RUC listo (eventos: 661, censored: 945) | tiempo 1m 5s · ETA 57s\n",
      "[ 60.0% · 9/15] Demografía y cohortes — Demografía (25 filas) y cohortes (6 filas) listos | tiempo 1m 5s · ETA 43s\n",
      "[ 66.7% · 10/15] Cantones y geografía — Cantones top calculados (7 filas) y métricas de concentración listas | tiempo 1m 5s · ETA 32s\n",
      "[ 73.3% · 11/15] Macro sectores y actividades — Macro sectores (21 filas) y actividades (10 filas) calculados. HHI=0.081 | tiempo 1m 5s · ETA 24s\n",
      "[ 80.0% · 12/15] KPIs de supervivencia — KPIs de supervivencia listos (mediana 228.0 meses) | tiempo 1m 5s · ETA 16s\n",
      "[ 86.7% · 13/15] Figuras base — 6 figuras base exportadas | tiempo 1m 6s · ETA 10s\n",
      "[ 93.3% · 14/15] Comparativas / KM estratificado — Comparativas generadas (6 tablas / 6 figuras) | tiempo 1m 8s · ETA 5s\n",
      "[100.0% · 15/15] Métricas ejecutivas — metrics.json y executive_kpis.csv generados | tiempo 1m 9s · ETA N/A\n",
      "Pipeline completado en 1m 9s.\n",
      "\n",
      "============================================================\n",
      "RESULTADOS\n",
      "============================================================\n",
      "[OK] BOLIVAR: outputs\\BOLIVAR\n",
      "\n",
      "Tiempo total: 68.94s (1.15 min)\n",
      "Promedio: 68.94s por provincia\n",
      "Exitosas: 1\n",
      "Fallidas: 0\n",
      "\n",
      "Cleanup: configs_override eliminado\n",
      "\n",
      "Proceso completado!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import importlib\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure we run from project root\n",
    "root = Path.cwd().resolve()\n",
    "while root != root.parent and not (root / \"configs\").exists():\n",
    "    root = root.parent\n",
    "os.chdir(root)\n",
    "\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.insert(0, str(root))\n",
    "\n",
    "# Optimizaciones de rendimiento\n",
    "print(\"=\"*60)\n",
    "print(\"INICIALIZANDO OPTIMIZACIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    from src.utils.performance import enable_pandas_performance, get_optimal_workers\n",
    "    enable_pandas_performance()\n",
    "    workers = get_optimal_workers()\n",
    "    print(f\"Optimizaciones habilitadas\")\n",
    "    print(f\"CPU cores disponibles: {os.cpu_count()}\")\n",
    "    print(f\"Workers configurados: {workers}\")\n",
    "except Exception as e:\n",
    "    print(f\"No se pudieron cargar optimizaciones: {e}\")\n",
    "    workers = 1\n",
    "\n",
    "# Ensure geopandas is available for heatmap rendering\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"geopandas\"])\n",
    "    import geopandas as gpd\n",
    "print(f\"geopandas {gpd.__version__}\")\n",
    "\n",
    "# Reload modules to pick up latest changes\n",
    "import src.etl.collapse_ruc as collapse_ruc\n",
    "import src.metrics.geografia as geografia\n",
    "import src.viz.figures as figures\n",
    "import src.reporting.export_artifacts as export_artifacts\n",
    "importlib.reload(collapse_ruc)\n",
    "importlib.reload(geografia)\n",
    "importlib.reload(figures)\n",
    "importlib.reload(export_artifacts)\n",
    "\n",
    "from src.reporting.export_artifacts import run_provincia\n",
    "\n",
    "provincias_cfg_path = Path(\"configs\") / \"provincias.yaml\"\n",
    "provincias_cfg = {}\n",
    "if provincias_cfg_path.exists():\n",
    "    provincias_cfg = yaml.safe_load(provincias_cfg_path.read_text(encoding=\"utf-8\")) or {}\n",
    "\n",
    "prov_map = provincias_cfg.get(\"provincias\", {}) or {}\n",
    "\n",
    "# Ordenar provincias con PROVINCIA al final\n",
    "all_provs = sorted(prov_map.keys())\n",
    "if \"PROVINCIA\" in all_provs:\n",
    "    all_provs.remove(\"PROVINCIA\")\n",
    "    available_provinces = all_provs + [\"PROVINCIA\"]\n",
    "else:\n",
    "    available_provinces = all_provs\n",
    "\n",
    "print(\"\\nProvincias disponibles:\")\n",
    "for idx, prov in enumerate(available_provinces, start=1):\n",
    "    print(f\"  {idx:02d}. {prov}\")\n",
    "\n",
    "# Seleccion de provincia o todas\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "run_all = input(\"Ejecutar todas las provincias? (s/N): \").strip().lower() == \"s\"\n",
    "\n",
    "# Modo paralelo\n",
    "use_parallel = False\n",
    "if run_all:\n",
    "    selected_province = None\n",
    "    if workers > 1:\n",
    "        parallel_choice = input(f\"Usar procesamiento PARALELO con {workers} workers? (S/n): \").strip().lower()\n",
    "        use_parallel = parallel_choice != 'n'\n",
    "        if use_parallel:\n",
    "            print(f\"Modo PARALELO activado - {workers}x mas rapido!\")\n",
    "        else:\n",
    "            print(\"Modo secuencial seleccionado\")\n",
    "else:\n",
    "    selected_province = None\n",
    "    while selected_province is None:\n",
    "        choice = input(\"\\nProvincia (numero o nombre): \").strip()\n",
    "        if not choice:\n",
    "            print(\"Debes ingresar una provincia valida.\")\n",
    "            continue\n",
    "        if choice.isdigit():\n",
    "            idx = int(choice)\n",
    "            if 1 <= idx <= len(available_provinces):\n",
    "                selected_province = available_provinces[idx - 1]\n",
    "                break\n",
    "        else:\n",
    "            choice_norm = choice.upper().strip()\n",
    "            if choice_norm in available_provinces:\n",
    "                selected_province = choice_norm\n",
    "                break\n",
    "        print(\"Provincia invalida, intenta otra vez.\")\n",
    "\n",
    "# Seleccion de intervalo\n",
    "interval_mode = input(\"\\nUsar todo el intervalo 2000-2024? (s/N): \").strip().lower() == \"s\"\n",
    "\n",
    "start_year = 2000\n",
    "end_year = 2024\n",
    "if not interval_mode:\n",
    "    presets = {\n",
    "        \"1\": (2000, 2009),\n",
    "        \"2\": (2010, 2016),\n",
    "        \"3\": (2017, 2024),\n",
    "    }\n",
    "    print(\"\\nIntervalos predefinidos:\")\n",
    "    print(\"  1) 2000-2009\")\n",
    "    print(\"  2) 2010-2016\")\n",
    "    print(\"  3) 2017-2024\")\n",
    "    preset_choice = input(\"Selecciona intervalo (1-3, Enter=2000-2009): \").strip()\n",
    "    if not preset_choice:\n",
    "        preset_choice = \"1\"\n",
    "    while preset_choice not in presets:\n",
    "        print(\"Intervalo invalido, intenta otra vez.\")\n",
    "        preset_choice = input(\"Selecciona intervalo (1-3): \").strip()\n",
    "    start_year, end_year = presets[preset_choice]\n",
    "\n",
    "print(f\"Intervalo: {start_year}-{end_year}\")\n",
    "\n",
    "# Modo publico activado automaticamente - no exporta data/raw_filtrado.csv\n",
    "public_mode = True\n",
    "print(\"\\nModo publico: activado (data anonimizado)\")\n",
    "\n",
    "def resolve_raw_path(province: str) -> str | None:\n",
    "    meta = prov_map.get(province.upper())\n",
    "    if not meta:\n",
    "        return None\n",
    "    return meta.get(\"raw_path\")\n",
    "\n",
    "def geo_path_for(province: str) -> Path:\n",
    "    geo_base = Path(\"data\") / \"geo\" / \"provincias\"\n",
    "    prov_folder = province.upper().strip().replace(\" \", \"_\")\n",
    "    path = geo_base / prov_folder / f\"{prov_folder.lower()}.geojson\"\n",
    "    if path.exists():\n",
    "        return path\n",
    "    return geo_base / \"ECUADOR.geojson\"\n",
    "\n",
    "def build_configs_override(start_year: int, end_year: int, use_all_years: bool) -> Path:\n",
    "    base = Path(\"configs\")\n",
    "    target = Path(\"notebooks\") / \"configs_override\"\n",
    "    target.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    global_cfg = yaml.safe_load((base / \"global.yaml\").read_text(encoding=\"utf-8\")) or {}\n",
    "    if not use_all_years:\n",
    "        global_cfg[\"window_start_year\"] = int(start_year)\n",
    "        global_cfg[\"window_end_year\"] = int(end_year)\n",
    "    (target / \"global.yaml\").write_text(yaml.safe_dump(global_cfg, sort_keys=False), encoding=\"utf-8\")\n",
    "\n",
    "    if (base / \"provincias.yaml\").exists():\n",
    "        (target / \"provincias.yaml\").write_text(\n",
    "            (base / \"provincias.yaml\").read_text(encoding=\"utf-8\"),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "    return target\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INICIANDO PROCESAMIENTO\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "cfg_dir = build_configs_override(start_year, end_year, interval_mode)\n",
    "outputs = []\n",
    "\n",
    "# Procesamiento optimizado\n",
    "from time import perf_counter\n",
    "start_time = perf_counter()\n",
    "\n",
    "if run_all and use_parallel:\n",
    "    # Modo paralelo\n",
    "    print(f\"Procesamiento PARALELO con {workers} workers\\n\")\n",
    "    \n",
    "    try:\n",
    "        from src.utils.parallel import process_provinces_parallel\n",
    "        \n",
    "        raw_paths_dict = {prov: resolve_raw_path(prov) for prov in available_provinces}\n",
    "        \n",
    "        results = process_provinces_parallel(\n",
    "            provincias=available_provinces,\n",
    "            configs_dir=str(cfg_dir),\n",
    "            raw_dir=\"data/raw\",\n",
    "            raw_paths=raw_paths_dict,\n",
    "            public_mode=public_mode,\n",
    "            max_workers=workers\n",
    "        )\n",
    "        \n",
    "        outputs = [{\"province\": r[\"provincia\"], \"output\": r[\"output\"], \"status\": r.get(\"status\", \"unknown\")} \n",
    "                   for r in results]\n",
    "    except Exception as e:\n",
    "        print(f\"Error en procesamiento paralelo: {e}\")\n",
    "        print(\"Recurriendo a procesamiento secuencial...\")\n",
    "        use_parallel = False\n",
    "\n",
    "if not use_parallel:\n",
    "    # Modo secuencial\n",
    "    provinces_to_process = available_provinces if run_all else [selected_province]\n",
    "    \n",
    "    for prov in provinces_to_process:\n",
    "        raw_path = resolve_raw_path(prov)\n",
    "        geo_path = geo_path_for(prov)\n",
    "        if not geo_path.exists():\n",
    "            print(f\"GeoJSON no encontrado para {prov}: {geo_path}\")\n",
    "        \n",
    "        try:\n",
    "            out_base = run_provincia(\n",
    "                prov,\n",
    "                configs_dir=str(cfg_dir),\n",
    "                raw_dir=\"data/raw\",\n",
    "                raw_path=raw_path,\n",
    "                public_mode=public_mode,\n",
    "            )\n",
    "            outputs.append({\"province\": prov, \"output\": str(out_base), \"status\": \"success\"})\n",
    "        except Exception as e:\n",
    "            print(f\"Error en {prov}: {e}\")\n",
    "            outputs.append({\"province\": prov, \"output\": None, \"status\": \"error\"})\n",
    "\n",
    "elapsed = perf_counter() - start_time\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "success_count = sum(1 for o in outputs if o.get(\"status\") == \"success\")\n",
    "error_count = len(outputs) - success_count\n",
    "\n",
    "for item in outputs:\n",
    "    status = \"[OK]\" if item.get(\"status\") == \"success\" else \"[ERROR]\"\n",
    "    print(f\"{status} {item['province']}: {item.get('output', 'ERROR')}\")\n",
    "\n",
    "print(f\"\\nTiempo total: {elapsed:.2f}s ({elapsed/60:.2f} min)\")\n",
    "if len(outputs) > 0:\n",
    "    print(f\"Promedio: {elapsed/len(outputs):.2f}s por provincia\")\n",
    "print(f\"Exitosas: {success_count}\")\n",
    "print(f\"Fallidas: {error_count}\")\n",
    "\n",
    "if use_parallel and workers > 1:\n",
    "    estimated_sequential = elapsed * workers\n",
    "    speedup = estimated_sequential / elapsed\n",
    "    print(f\"\\nSpeedup estimado: {speedup:.1f}x mas rapido que secuencial\")\n",
    "\n",
    "shutil.rmtree(cfg_dir, ignore_errors=True)\n",
    "print(f\"\\nCleanup: configs_override eliminado\")\n",
    "print(\"\\nProceso completado!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
